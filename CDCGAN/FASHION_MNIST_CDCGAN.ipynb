{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FASHION_MNIST_CDCGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OjISASMcL1p",
        "colab_type": "text"
      },
      "source": [
        "# Conditional Deep Convolutional Generative Adversarial Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCApHGKrVl-r",
        "colab_type": "text"
      },
      "source": [
        "If you have not gone through my DCGAN notebook, than please do so by clicking on this [Link](https://github.com/raja-git-ai/GAN/blob/master/DCGAN/FASHION_MNIST_DCGAN.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5saufafTcAQz",
        "colab_type": "text"
      },
      "source": [
        "### Brief about CDCGAN\n",
        "1.) CDCGAN basically refers to generating an image or a multidimensional image like array on the basis of user input or directed input.<br>\n",
        "2.) In our current implementation we can ask the generator model to generate a class of image like bag shoes, tshirt's etc by givin user input.<br>\n",
        "3.) Basically we specify a class of image and the network spits out relevent image/data.\n",
        "\n",
        "4.) where as a DCGAN spits out image of any class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpCiwi_kfPxG",
        "colab_type": "text"
      },
      "source": [
        "5.) CDCGAN Network architecture.\n",
        "\n",
        "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/05/Example-of-a-Conditional-Generator-and-a-Conditional-Discriminator-in-a-Conditional-Generative-Adversarial-Network-1024x887.png\" width=\"500\"/><br>\n",
        "Taken from Conditional Generative Adversarial Nets, 2014.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSV8pZr_k3a3",
        "colab_type": "text"
      },
      "source": [
        "### Implementation idea\n",
        "#### Generator :- \n",
        "1.) We create a Generator which can take random noise and class of image(9 for shoe, 8 for bag etc) as input.<br>\n",
        "2.) Random noise is resized to a shape of image with multiple channel.<br>\n",
        "3.) Class of image will also be resized to shape of a image but with single channel.<br>\n",
        "\n",
        "#### Descriminator :- \n",
        "1.) We create a descriminator which can take a multichannel real image or multichannel fake image produced by generator. <br>\n",
        "2.) Class label of image and a label which specifies whether the ultichannel image is fake or real.<br>\n",
        "3.) Generator and Descriminator are trained simultaniously.<br>\n",
        "4.) Finally the generator is picked up and used to prduce veriety of images within the class provided by user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrkJZgSvdLzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing neccessary libraries\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets.fashion_mnist import load_data\n",
        "from tensorflow.keras import Sequential,Model\n",
        "from tensorflow.keras.layers import Conv2D,Reshape,Conv2DTranspose,Dense,Flatten,LeakyReLU,Dropout,Embedding,Input,Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWWuTpdKfXap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c2a9e104-e03f-49d8-99c7-f14a23f59c7f"
      },
      "source": [
        "# Loading the data \n",
        "(X_train,y_train),(X_test,y_test) = load_data()\n",
        "X_train = np.expand_dims(X_train,axis=-1)\n",
        "X_test = np.expand_dims(X_test,axis=1)\n",
        "X_train = X_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "# Resizing image\n",
        "X_train = (X_train - 127.5)/127.5\n",
        "X_test = (X_test - 127.5)/127.5\n",
        "print(\"Shape of taining examples-> \",X_train.shape,y_train.shape)\n",
        "print(\"Shape of test examples-> \",X_test.shape,y_test.shape)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of taining examples->  (60000, 28, 28, 1) (60000,)\n",
            "Shape of test examples->  (10000, 1, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMykJ1dHoV--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e039dfd-7805-4734-ec41-0f5b9fbb1275"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GA7np8i99yC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ea4cdc19-6242-4d2a-b737-c0e2ff571c04"
      },
      "source": [
        "X_train.min()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWBj1k9ti8-i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1909b532-4d89-42db-ced6-a7ca6dd51576"
      },
      "source": [
        "# We can see that lables are presented as numbers , which going forward we will create a exact lable mapping.\n",
        "y_test[:10]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02KJh5JGjWb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "698b42a1-61b5-4958-9d04-64604f1a0043"
      },
      "source": [
        "# Plot raw pixel data\n",
        "plt.imshow(X_train[0,:,:,0],cmap='gray_r')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f32af774c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B3nvzs1HfpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (28,28,1)\n",
        "num_classes = 10\n",
        "noise_points = 100\n",
        "# Define descriminator \n",
        "def get_descriminator():\n",
        "  #1. We need to define one embedding layer \n",
        "  #2. We have to resize the embedding layer to match up with the conv layer and will have to blow it up to match the conv layer sizes\n",
        "  # Preparing the Embedding Layer\n",
        "  # Plan is to add the class label as a channel in the overall image \n",
        "  # 1. Taking the input\n",
        "  input_label = Input(shape=(1,))\n",
        "  # 2. Creating a 50 dimensional embdding out of the input\n",
        "  embedding = Embedding(input_dim=num_classes,output_dim=50)(input_label)\n",
        "  # 3. Blowing up the input to a shape of 28*28\n",
        "  embedding = Dense(input_shape[0]*input_shape[1])(embedding)\n",
        "  # 4. Creating a 28*28 square matrix out of dense layer\n",
        "  embedding = Reshape((input_shape[0],input_shape[1],1))(embedding)\n",
        "\n",
        "  ########################################################3\n",
        "  # 5. Taking the image input\n",
        "  input_image = Input(shape=input_shape)\n",
        "  \n",
        "  # 6. Concatenating the input image with the class label from step 4\n",
        "  class_and_image = Concatenate()([input_image,embedding])\n",
        "\n",
        "  # Preparing the conv layer\n",
        "  convolve = Conv2D(128,kernel_size=(4,4),strides=(1,1),padding='same')(class_and_image)\n",
        "  convolve = LeakyReLU(alpha=0.2)(convolve)\n",
        "\n",
        "  convolve = Conv2D(128,kernel_size=(3,3),strides=(2,2),padding='same')(convolve)\n",
        "  convolve = LeakyReLU()(convolve)\n",
        "\n",
        "  convolve = Flatten()(convolve)\n",
        "  convolve = Dropout(0.2)(convolve)\n",
        "\n",
        "  convolve = Dense(1,activation='sigmoid')(convolve)\n",
        "  \n",
        "  model = Model([input_image,input_label],convolve)\n",
        "  model.compile(loss='binary_crossentropy',optimizer = Adam(lr=0.002),metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0XTzomvW0P5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678
        },
        "outputId": "433160ee-7bf3-48cc-f8f2-6aa201ec3fe1"
      },
      "source": [
        "# Getting descriminator\n",
        "descriminator = get_descriminator()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_25\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 1, 50)        500         input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1, 784)       39984       embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 28, 28, 1)    0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 28, 28, 2)    0           input_14[0][0]                   \n",
            "                                                                 reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 28, 28, 128)  4224        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, 28, 28, 128)  0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 14, 14, 128)  147584      leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 14, 14, 128)  0           conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 25088)        0           leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 25088)        0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1)            25089       dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 217,381\n",
            "Trainable params: 217,381\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikbYWYS1W8Kx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define generator\n",
        "def get_gnerator():\n",
        "  # Goal is to take class label as input and add it with random noise.\n",
        "  # Further blow it up to form a square matrix representing 2 channel image \n",
        "\n",
        "  # 1. Creating embedding layer\n",
        "  input_label = Input(shape=(1,))\n",
        "  embedding = Embedding(num_classes,50)(input_label)\n",
        "  tot_nodes = 1* 7*7\n",
        "  embedding = Dense(tot_nodes)(embedding)\n",
        "  embedding = Reshape((7,7,1))(embedding)\n",
        "\n",
        "  # 2. Creating layer to ingest random noise i.e feeding the latent layer\n",
        "  latent = Input(shape=(noise_points,))\n",
        "  tot_nodes = 128*7*7\n",
        "  gen = Dense(tot_nodes)(latent)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "  # Reshaping the layer to be a size of 7*7*128\n",
        "  gen = Reshape((7,7,128))(gen)\n",
        "  # Merging the embedding layer representing class with noise layer\n",
        "  gen = Concatenate()([gen,embedding])\n",
        "  # Upsample to 14 * 14 \n",
        "  gen = Conv2DTranspose(filters=128,kernel_size= (5,5),strides=(2,2),padding='same')(gen)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen)\n",
        "\n",
        "  # Upsample to 28*28 \n",
        "  gen = Conv2DTranspose(filters=128,kernel_size = (4,4),strides=(2,2),padding='same')(gen)\n",
        "  gen = LeakyReLU(alpha=0.2)(gen) \n",
        "  # Out layer \n",
        "  out_layer = Conv2D(1,(7,7),activation='tanh',padding='same')(gen)\n",
        "\n",
        "  # Define model \n",
        "  model = Model([latent,input_label],out_layer)\n",
        "  print(model.summary())\n",
        "  return model "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R361-dvWNx88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "97725ad6-4f51-42be-facd-e8ed4830641c"
      },
      "source": [
        "# Get descriminator\n",
        "generator = get_gnerator()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_27\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 6272)         633472      input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 1, 50)        500         input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 6272)         0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1, 49)        2499        embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 7, 7, 128)    0           leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 7, 7, 1)      0           dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 7, 7, 129)    0           reshape_11[0][0]                 \n",
            "                                                                 reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 14, 14, 128)  412928      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 14, 14, 128)  0           conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 28, 28, 128)  262272      leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 28, 28, 128)  0           conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 1)    6273        leaky_re_lu_19[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 1,317,944\n",
            "Trainable params: 1,317,944\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQZ_VCgIYQAr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define CDCGAN model \n",
        "def cdcgan(generator,descriminator):\n",
        "  descriminator.trainable = False\n",
        "  gen_noise,gen_label = generator.input\n",
        "  gen_output = generator.output \n",
        "  # output from descriminator\n",
        "  cdcgan_output = descriminator([gen_output,gen_label])\n",
        "  # defining model\n",
        "  cdcgan_model = Model([gen_noise,gen_label],cdcgan_output)\n",
        "  cdcgan_model.compile(loss='binary_crossentropy',optimizer=Adam(learning_rate=0.0002,beta_1=0.5))\n",
        "  print(cdcgan_model.summary())\n",
        "  return cdcgan_model"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIGhbR4SdTqR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "outputId": "477e4d94-7e87-4f83-e513-b52626ec7be4"
      },
      "source": [
        "cdcgan_model = cdcgan(generator,descriminator)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_29\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_16 (InputLayer)           [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 6272)         633472      input_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 1, 50)        500         input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, 6272)         0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1, 49)        2499        embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 7, 7, 128)    0           leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 7, 7, 1)      0           dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 7, 7, 129)    0           reshape_11[0][0]                 \n",
            "                                                                 reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTrans (None, 14, 14, 128)  412928      concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, 14, 14, 128)  0           conv2d_transpose_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_7 (Conv2DTrans (None, 28, 28, 128)  262272      leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 28, 28, 128)  0           conv2d_transpose_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 1)    6273        leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "functional_25 (Functional)      (None, 1)            217381      conv2d_11[0][0]                  \n",
            "                                                                 input_15[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 1,535,325\n",
            "Trainable params: 1,317,944\n",
            "Non-trainable params: 217,381\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZzyIgBidyBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get batch of training data\n",
        "def get_actual_data(batch_size,X_train,y_train):\n",
        "  random_idx = np.random.randint(0,X_train.shape[0],batch_size)\n",
        "  X_sample = X_train[random_idx]\n",
        "  real_lables = y_train[random_idx]\n",
        "  # LAbel for the GAN which indicates these are actual images from the dataset\n",
        "  y_real = np.ones((batch_size,1))\n",
        "  return X_sample,real_lables,y_real\n",
        "\n",
        "def generate_latent_points(latent_dim,n_samples,n_classes=10):\n",
        "  # Generate random points in latent sapce\n",
        "  X_rand_latent = np.random.randn(latent_dim*n_samples)\n",
        "  X_rand_latent = X_rand_latent.reshape(n_samples,latent_dim)\n",
        "  y_rand_label = np.random.randint(0,n_classes,n_samples)\n",
        "  return X_rand_latent,y_rand_label\n",
        "\n",
        "def generate_random_fake_samples(batch_size,classes = 10):\n",
        "    X_fake,fake_lables = generate_latent_points(noise_points,batch_size)\n",
        "    # Creating images out of fake samples \n",
        "    fake_images = generator([X_fake,fake_lables])\n",
        "    y_fake  = np.zeros((batch_size,1))\n",
        "\n",
        "    return fake_images,fake_lables,y_fake "
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyO4xiEmGklb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(generator,descriminator,X_train,y_train,noise_points,num_epocs=100,num_batch=128):\n",
        "\n",
        "    batch_per_epocs = X_train.shape[0]//num_batch\n",
        "    half_batch = num_batch//2\n",
        "\n",
        "    for i in range(num_epocs):\n",
        "      for j in range(batch_per_epocs):\n",
        "        X_real_sample,y_pred_real_sample,y_real = get_actual_data(num_batch,X_train,y_train)\n",
        "        # Train Descriminator on real samples and update weights\n",
        "        descriminator_loss1,_ = descriminator.train_on_batch([X_real_sample,y_pred_real_sample],y_real)\n",
        "        # Get Fake data or generated Data\n",
        "        X_fake,fake_lables,y_fake = generate_random_fake_samples(num_batch)\n",
        "        # Train Descriminator on fake results \n",
        "        descriminator_loss2,_ = descriminator.train_on_batch([X_fake,fake_lables],y_fake)\n",
        "        # Generate latent points to train the CGAN\n",
        "        X_rand_latent,y_rand_label = generate_latent_points(noise_points,num_batch)\n",
        "        # We will create an array of 1 for the output label of fake samples \n",
        "        # IT will help us to calculate the GAN loss\n",
        "        y_gan = np.ones((num_batch,1))\n",
        "        gen_loss = cdcgan_model.train_on_batch([X_rand_latent,y_rand_label],y_gan)\n",
        "        # Print summary of loss per cycle \n",
        "      print(\"batch, epoch, descriminator loss 1,2 gan loss\")\n",
        "      print(i,j,descriminator_loss1,descriminator_loss2,gen_loss)\n",
        "    # Save the model after training \n",
        "    generator.save_weights(\"cdcgan_model.h5\")"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl_bnXN8CKP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Begin training \n",
        "train(generator,descriminator,X_train,y_train,noise_points,num_epocs=100,num_batch=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C_qUM8VpOC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load existing model \n",
        "generator.load_weights(\"cdcgan_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5N0MGakLp-2",
        "colab_type": "text"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0Sx2ipq8pMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate latent/random points for 3 random inputs\n",
        "X_rand_latent,y_rand_label = generate_latent_points(noise_points,3)\n",
        "y_rand_label = np.array([9,8,7])"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9aWs_7cOUoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our object dictionary\n",
        "obj_dict = {'t-shirt':0, 'trouser':1, 'pullover':2, 'dress':3, 'coat':4, 'sandal':5,\n",
        "            'shirt':6, 'sneaker':7, 'bag':8,'ankle boot':9}"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBs954JKL-sD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We are producing generated images for class label \n",
        "# 1. Boot\n",
        "# 2. Bag \n",
        "# 3. Sneaker\n",
        "y_pred = generator.predict([X_rand_latent,y_rand_label])"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W1dn-z4MVAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "16b752e3-4af7-41dc-b642-ed7c574ed27b"
      },
      "source": [
        "# So as per our key value dictionary we are have generated below image for ankle boot\n",
        "# Which referrs to key 9\n",
        "plt.imshow(y_pred[0,:,:,0],cmap='gray_r')"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f316f6b0828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CacXW0qqMYNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "3cccc19a-5b84-4ec5-dc1c-513e230959d3"
      },
      "source": [
        "# So as per our key value dictionary we are have generated below image for a bag\n",
        "# Which referrs to key 8\n",
        "plt.imshow(y_pred[1,:,:,0],cmap='gray_r')"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f316f718470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9xTkNI5PfJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "14bbd53f-9f43-43eb-b5ef-8e04c6d1d14c"
      },
      "source": [
        "# So as per our key value dictionary we are have generated below image for a sneaker or close to sneaker\n",
        "# Which referrs to key 7\n",
        "plt.imshow(y_pred[2,:,:,0],cmap='gray_r')"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f31735fa080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKw4U9a3QMxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}